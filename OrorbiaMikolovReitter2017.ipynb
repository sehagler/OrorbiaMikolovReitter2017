{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delta Recurrent Neural Network (Delta-RNN) Framework\n",
    "#\n",
    "# This gives an implementation of the Delta-RNN framework given in Ororbia et al. 2017, arXiv:1703.08864 [cs.CL], \n",
    "# https://arxiv.org/abs/1703.08864 using Python and Tensorflow.\n",
    "#\n",
    "# This IPython Notebook provides an example of how to call the associated library of Python scripts.  \n",
    "# Ororbia et al. should be consulted to make sure of the correct hyperparameter values.\n",
    "#\n",
    "# Stuart Hagler, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# Local Imports\n",
    "sys.path.insert(0, 'python')\n",
    "from gru import gru_graph\n",
    "from peephole_lstm import peephole_lstm_graph\n",
    "from read_data import read_data\n",
    "from scrn import scrn_graph\n",
    "from srn import srn_graph\n",
    "from tokens import text_elements_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Flags\n",
    "cell_flg = 2     # 1 for GRU (uses h_size)\n",
    "                 # 2 for Peephole LSTM (uses h_size)\n",
    "                 # 3 for SCRN (uses alpha, c_size, and h_size)\n",
    "                 # 4 for SRN (uses h_size)\n",
    "usecase_flg = 2  # 1 for predicting letters\n",
    "                 # 2 for predicting words with cutoff for infrequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network hyperparameters\n",
    "alpha = 0.95                        #\n",
    "c_size = 10                         # Dimension of the state vector\n",
    "h_size = 100                        # Dimension of the hidden vector\n",
    "\n",
    "# Training hyperparameters\n",
    "num_training_unfoldings = 50        # Number of training unfoldings\n",
    "    \n",
    "# General network hyperparameters\n",
    "word_frequency_cutoff = 50          # Cutoff for infrequent words for usecase_flg = 2\n",
    "\n",
    "# General training hyperparameters\n",
    "base_training_batch_size = 32       # Training batch size across all towers\n",
    "clip_norm = 1.25                    # Norm for gradient clipping\n",
    "learning_decay = 1/2                # Multiplier to decay the learn rate when required\n",
    "learning_rate = 0.05                # Initial learning rate\n",
    "momentum = 0.9                      # Momentum for training\n",
    "num_epochs = 50                     # Total number of epochs to run the algorithm\n",
    "num_validation_unfoldings = 1000    # Number of validation unfoldings\n",
    "optimization_frequency = 5          # Number of unfoldings before optimization step\n",
    "summary_frequency = 500             # Summary information is displayed after training this many batches\n",
    "validation_batch_size = 32          # Validation batch size for each tower\n",
    "\n",
    "# Cluster\n",
    "num_gpus = 1                        # Number of GPUs available\n",
    "\n",
    "# Logging\n",
    "logdir = '/tmp/tensorflow/log/'\n",
    "\n",
    "# Data file\n",
    "filename = 'data/text8.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare training, validation, test data sets\n",
    "num_towers = num_gpus\n",
    "training_batch_size = base_training_batch_size // num_towers\n",
    "raw_data = read_data(usecase_flg, filename)\n",
    "data, dictionary, reverse_dictionary, vocabulary_size = text_elements_to_tokens(usecase_flg, raw_data, \n",
    "                                                                                word_frequency_cutoff)\n",
    "training_size = math.floor((9/11)*len(raw_data)/num_towers)\n",
    "validation_size = math.floor((1/11)*len(raw_data)/num_towers)\n",
    "test_size = math.floor((1/11)*len(raw_data)/num_towers)\n",
    "training_text = []\n",
    "validation_text = []\n",
    "test_text = []\n",
    "for i in range(num_towers):\n",
    "    training_text.append(data[i*training_size:(i+1)*training_size])\n",
    "    validation_text.append(data[num_towers*training_size + i*validation_size: \\\n",
    "                                num_towers*training_size + (i+1)*validation_size])\n",
    "    test_text.append(data[num_towers*(training_size + validation_size) + i*test_size: \\\n",
    "                          num_towers*(training_size + validation_size) + (i+1)*test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 18275\n",
      "Training Batch Generator:\n",
      "     Tower: 0\n",
      "          Input Text Size: 13913351\n",
      "          Cut Text Size: 13912000\n",
      "          Subtext Size: 434750\n",
      "          Dropped Text Size: 1351\n",
      "          Effective Batch Size: 1600\n",
      "          Number of Batches: 8695\n",
      "Validation Batch Generator:\n",
      "     Tower: 0\n",
      "          Input Text Size: 1545927\n",
      "          Cut Text Size: 1536000\n",
      "          Subtext Size: 48000\n",
      "          Dropped Text Size: 9927\n",
      "          Effective Batch Size: 32000\n",
      "          Number of Batches: 48\n",
      "Initialized\n",
      "Epoch: 1  Learning Rate: 0.05\n",
      "     Total Batches: 500  Current Batch: 500  Cost: 6.90\n",
      "     Total Batches: 1000  Current Batch: 1000  Cost: 7.42\n",
      "     Total Batches: 1500  Current Batch: 1500  Cost: 7.04\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary Size: %d' % vocabulary_size)\n",
    "\n",
    "# Initialize graph\n",
    "if cell_flg == 1:\n",
    "    graph = gru_graph(num_gpus, alpha, c_size, h_size, vocabulary_size, num_training_unfoldings, \n",
    "                      num_validation_unfoldings, training_batch_size, validation_batch_size, optimization_frequency)\n",
    "elif cell_flg == 2:\n",
    "    graph = peephole_lstm_graph(num_gpus, alpha, c_size, h_size, vocabulary_size, num_training_unfoldings, \n",
    "                                num_validation_unfoldings, training_batch_size, validation_batch_size, \n",
    "                                optimization_frequency)\n",
    "elif cell_flg == 3:\n",
    "    graph = scrn_graph(num_gpus, alpha, c_size, h_size, vocabulary_size, num_training_unfoldings, \n",
    "                       num_validation_unfoldings, training_batch_size, validation_batch_size, optimization_frequency)\n",
    "elif cell_flg == 4:\n",
    "    graph = srn_graph(num_gpus, alpha, c_size, h_size, vocabulary_size, num_training_unfoldings, \n",
    "                      num_validation_unfoldings, training_batch_size, validation_batch_size, optimization_frequency)\n",
    "    \n",
    "# Train graph\n",
    "graph.train(learning_rate, learning_decay, momentum, clip_norm, num_epochs, summary_frequency, training_text, \n",
    "            validation_text, logdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
